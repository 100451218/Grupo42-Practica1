{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100451218/Grupo42-Practica1/blob/main/Copia_de_Copia_de_Copia_de_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8Z1eajr-0a"
      },
      "source": [
        "100451218- Sergi Vila\n",
        "100451058-Daniel Obreo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdRs8jjy5_mo"
      },
      "source": [
        "# Análisis exploratorio de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYkeVq-6WT0b"
      },
      "source": [
        "Para el análisis exploratorio de datos vamos a observar:\n",
        "1. Qué valores son siempre 0\n",
        "2. Qué valores son constantes\n",
        "3. Qué correlación hay entre columnas\n",
        "4. Qué correlación hay entre las columnas y la salida\n",
        "5. Hipótesis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW3z963r6xCD"
      },
      "source": [
        "### Importamos las librerías y cargamos los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gvfEN5UrgTS",
        "outputId": "ffde1dff-f49a-4c57-d5b8-450160426862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pd in /usr/local/lib/python3.9/dist-packages (0.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from seaborn) (1.4.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pd\n",
        "!pip install seaborn\n",
        "\n",
        "import pandas as pd\n",
        "#Importamos los dos conjuntos de datos.\n",
        "disp_df = pd.read_csv(\"disp_st42ns1.txt.bz2\",\n",
        " compression=\"bz2\", \n",
        " index_col=0)\n",
        "comp_df = pd.read_csv(\"comp_st42ns1.txt.bz2\", \n",
        " compression=\"bz2\", \n",
        " index_col=0)\n",
        "#print(disp_df['apcp_sf1_1'][0])\n",
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8Mm9Tj7TMc"
      },
      "source": [
        "### Comprobamos valores a 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2kKbVD-7XS7",
        "outputId": "ff2f0382-3888-430e-da08-9f0e5239cda8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uswrf_s1_1\n"
          ]
        }
      ],
      "source": [
        "for i in disp_df:\n",
        "  if disp_df[i].sum()==0:\n",
        "    print(i)\n",
        "  \"\"\"Con esta linea podemos ver las filas con todos los valores en 0, ya que \n",
        "  vemos después que no hay números negativos\"\"\"\n",
        "  # print(i ,\": \",disp_df[i].value_counts())\n",
        "  for k in range(len(disp_df[i])):\n",
        "    if disp_df[i][k]<0:\n",
        "      \"\"\"Si hubiera un número negativo se imprimiría hay\"\"\"\n",
        "      print(\"Hay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROtYg7BPT1_"
      },
      "source": [
        "Hemos podido observar que la columna uswrf_s1_1 es inútil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvX_7Xgi7f4m"
      },
      "source": [
        "### Comprobamos valores constantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoQ1g-9jPZRJ",
        "outputId": "5ed8f83e-607b-4228-fd32-500c11bc82fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uswrf_s1_1\n"
          ]
        }
      ],
      "source": [
        "#También vamos a comprobar si el valor es constante\n",
        "\"\"\"print(disp_df[\"uswrf_s1_1\"].nunique())\"\"\"\n",
        "#Cómo hemos dicho antes, sólo hay un número único\n",
        "for i in disp_df:\n",
        "  if disp_df[i].nunique()==1:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlppAEdO7lwe"
      },
      "source": [
        "Sale la misma columna ya que es constante en 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC3ewTwP7ttI"
      },
      "source": [
        "### Comprobamos correlación entre columnas\n",
        "\n",
        "Vamos a mirar para un umbral de 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq1zcsNlQvS9",
        "outputId": "31015021-e98a-40b0-f448-7b70e9603d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlwrf_s1_1 ,  dlwrf_s2_1  :  0.9703837115052251\n",
            "dlwrf_s1_1 ,  dlwrf_s3_1  :  0.9618644397452982\n",
            "dlwrf_s2_1 ,  dlwrf_s3_1  :  0.9941484165303395\n",
            "dlwrf_s3_1 ,  dlwrf_s4_1  :  0.9714313070426391\n",
            "dlwrf_s3_1 ,  dlwrf_s5_1  :  0.9628906707604897\n",
            "dlwrf_s4_1 ,  dlwrf_s5_1  :  0.9976436933451329\n",
            "dswrf_s2_1 ,  dswrf_s3_1  :  0.9571667754289556\n",
            "dswrf_s2_1 ,  uswrf_s2_1  :  0.9942986544231128\n",
            "dswrf_s3_1 ,  uswrf_s2_1  :  0.964297736448637\n",
            "dswrf_s3_1 ,  uswrf_s3_1  :  0.9620365523744548\n",
            "dswrf_s4_1 ,  dswrf_s5_1  :  0.9846653842283272\n",
            "pres_ms1_1 ,  pres_ms2_1  :  0.9861133756671324\n",
            "pres_ms1_1 ,  pres_ms3_1  :  0.9501939300486043\n",
            "pres_ms2_1 ,  pres_ms3_1  :  0.9855174686825475\n",
            "pres_ms3_1 ,  pres_ms4_1  :  0.9852195616314235\n",
            "pres_ms3_1 ,  pres_ms5_1  :  0.9503729775888822\n",
            "pres_ms4_1 ,  pres_ms5_1  :  0.983982500363903\n",
            "pwat_ea1_1 ,  pwat_ea2_1  :  0.987536536664307\n",
            "pwat_ea1_1 ,  pwat_ea3_1  :  0.963475239218834\n",
            "pwat_ea2_1 ,  pwat_ea3_1  :  0.9888327077899062\n",
            "pwat_ea2_1 ,  pwat_ea4_1  :  0.9641615077236247\n",
            "pwat_ea3_1 ,  pwat_ea4_1  :  0.9876766173812521\n",
            "pwat_ea3_1 ,  pwat_ea5_1  :  0.9599805697947899\n",
            "pwat_ea4_1 ,  pwat_ea5_1  :  0.9866668820482905\n",
            "spfh_2m1_1 ,  spfh_2m2_1  :  0.9774693823508754\n",
            "spfh_2m2_1 ,  spfh_2m3_1  :  0.9785184403976822\n",
            "spfh_2m3_1 ,  spfh_2m4_1  :  0.9796009267620638\n",
            "spfh_2m3_1 ,  spfh_2m5_1  :  0.9582539207433676\n",
            "spfh_2m4_1 ,  spfh_2m5_1  :  0.9881530174283563\n",
            "tcdc_ea1_1 ,  tcolc_e1_1  :  0.999977884315217\n",
            "tcdc_ea2_1 ,  tcolc_e2_1  :  0.9999803755794225\n",
            "tcdc_ea3_1 ,  tcolc_e3_1  :  0.9999795855646263\n",
            "tcdc_ea4_1 ,  tcolc_e4_1  :  0.999975898110073\n",
            "tcdc_ea5_1 ,  tcolc_e5_1  :  0.9999715058573335\n",
            "tmax_2m1_1 ,  tmax_2m2_1  :  0.9724897672414627\n",
            "tmax_2m1_1 ,  tmin_2m1_1  :  0.989056386514375\n",
            "tmax_2m1_1 ,  tmin_2m2_1  :  0.9833942905012109\n",
            "tmax_2m1_1 ,  tmin_2m3_1  :  0.9830352978705852\n",
            "tmax_2m1_1 ,  tmp_2m_1_1  :  0.9873969132950682\n",
            "tmax_2m1_1 ,  tmp_2m_2_1  :  0.9688954299253763\n",
            "tmax_2m1_1 ,  tmp_sfc1_1  :  0.9844868652232457\n",
            "tmax_2m1_1 ,  tmp_sfc2_1  :  0.9575154013071906\n",
            "tmax_2m1_1 ,  ulwrf_s1_1  :  0.9924162717155949\n",
            "tmax_2m1_1 ,  ulwrf_s2_1  :  0.9743550672162224\n",
            "tmax_2m1_1 ,  ulwrf_s3_1  :  0.9609302989327574\n",
            "tmax_2m2_1 ,  tmax_2m3_1  :  0.985671383790568\n",
            "tmax_2m2_1 ,  tmax_2m4_1  :  0.9674088612972191\n",
            "tmax_2m2_1 ,  tmax_2m5_1  :  0.9661700588392864\n",
            "tmax_2m2_1 ,  tmin_2m1_1  :  0.982260351500139\n",
            "tmax_2m2_1 ,  tmin_2m2_1  :  0.9864003795613444\n",
            "tmax_2m2_1 ,  tmin_2m3_1  :  0.9864362288141282\n",
            "tmax_2m2_1 ,  tmin_2m4_1  :  0.9809370434214474\n",
            "tmax_2m2_1 ,  tmin_2m5_1  :  0.9743721937876045\n",
            "tmax_2m2_1 ,  tmp_2m_1_1  :  0.9831565195310004\n",
            "tmax_2m2_1 ,  tmp_2m_2_1  :  0.9992834032396157\n",
            "tmax_2m2_1 ,  tmp_2m_3_1  :  0.9834195825162696\n",
            "tmax_2m2_1 ,  tmp_2m_4_1  :  0.9639465379725813\n",
            "tmax_2m2_1 ,  tmp_2m_5_1  :  0.9647323215612712\n",
            "tmax_2m2_1 ,  tmp_sfc1_1  :  0.9744486594777503\n",
            "tmax_2m2_1 ,  tmp_sfc2_1  :  0.9918925672159637\n",
            "tmax_2m2_1 ,  tmp_sfc3_1  :  0.9601906768001106\n",
            "tmax_2m2_1 ,  tmp_sfc4_1  :  0.950573234613489\n",
            "tmax_2m2_1 ,  tmp_sfc5_1  :  0.9654486189767068\n",
            "tmax_2m2_1 ,  ulwrf_s1_1  :  0.9715881682393587\n",
            "tmax_2m2_1 ,  ulwrf_s2_1  :  0.9892425513588253\n",
            "tmax_2m2_1 ,  ulwrf_s3_1  :  0.9909487821493767\n",
            "tmax_2m2_1 ,  ulwrf_s4_1  :  0.9548744393127798\n",
            "tmax_2m2_1 ,  ulwrf_s5_1  :  0.9599134944218464\n",
            "tmax_2m3_1 ,  tmax_2m4_1  :  0.9932155319672418\n",
            "tmax_2m3_1 ,  tmax_2m5_1  :  0.9918528530224062\n",
            "tmax_2m3_1 ,  tmin_2m1_1  :  0.9550113483380075\n",
            "tmax_2m3_1 ,  tmin_2m2_1  :  0.9617950175772039\n",
            "tmax_2m3_1 ,  tmin_2m3_1  :  0.9623980222433619\n",
            "tmax_2m3_1 ,  tmin_2m4_1  :  0.9986140521743142\n",
            "tmax_2m3_1 ,  tmin_2m5_1  :  0.9887081844388815\n",
            "tmax_2m3_1 ,  tmp_2m_1_1  :  0.9561744020698948\n",
            "tmax_2m3_1 ,  tmp_2m_2_1  :  0.987335897105345\n",
            "tmax_2m3_1 ,  tmp_2m_3_1  :  0.9994790214287826\n",
            "tmax_2m3_1 ,  tmp_2m_4_1  :  0.990917632685966\n",
            "tmax_2m3_1 ,  tmp_2m_5_1  :  0.9791567373613668\n",
            "tmax_2m3_1 ,  tmp_sfc2_1  :  0.9787804410917824\n",
            "tmax_2m3_1 ,  tmp_sfc3_1  :  0.9808274729878784\n",
            "tmax_2m3_1 ,  tmp_sfc4_1  :  0.9750511698471924\n",
            "tmax_2m3_1 ,  tmp_sfc5_1  :  0.970316269000124\n",
            "tmax_2m3_1 ,  ulwrf_s2_1  :  0.96279492003488\n",
            "tmax_2m3_1 ,  ulwrf_s3_1  :  0.9814956435371066\n",
            "tmax_2m3_1 ,  ulwrf_s4_1  :  0.9769621879732242\n",
            "tmax_2m3_1 ,  ulwrf_s5_1  :  0.97825377218904\n",
            "tmax_2m4_1 ,  tmax_2m5_1  :  0.9997763091522931\n",
            "tmax_2m4_1 ,  tmin_2m4_1  :  0.995227401324633\n",
            "tmax_2m4_1 ,  tmin_2m5_1  :  0.9902281962655157\n",
            "tmax_2m4_1 ,  tmp_2m_2_1  :  0.9704273089707779\n",
            "tmax_2m4_1 ,  tmp_2m_3_1  :  0.9942060791070809\n",
            "tmax_2m4_1 ,  tmp_2m_4_1  :  0.9993337962089638\n",
            "tmax_2m4_1 ,  tmp_2m_5_1  :  0.9864449361164253\n",
            "tmax_2m4_1 ,  tmp_sfc2_1  :  0.9635448652291986\n",
            "tmax_2m4_1 ,  tmp_sfc3_1  :  0.9800786432147343\n",
            "tmax_2m4_1 ,  tmp_sfc4_1  :  0.9851795066135184\n",
            "tmax_2m4_1 ,  tmp_sfc5_1  :  0.9734379959027885\n",
            "tmax_2m4_1 ,  ulwrf_s3_1  :  0.9675001985447437\n",
            "tmax_2m4_1 ,  ulwrf_s4_1  :  0.9815524520981147\n",
            "tmax_2m4_1 ,  ulwrf_s5_1  :  0.9839305310878618\n",
            "tmax_2m5_1 ,  tmin_2m4_1  :  0.9939262271086854\n",
            "tmax_2m5_1 ,  tmin_2m5_1  :  0.9900034740853147\n",
            "tmax_2m5_1 ,  tmp_2m_2_1  :  0.9692202856726265\n",
            "tmax_2m5_1 ,  tmp_2m_3_1  :  0.9928207401008318\n",
            "tmax_2m5_1 ,  tmp_2m_4_1  :  0.9992067250706518\n",
            "tmax_2m5_1 ,  tmp_2m_5_1  :  0.9877793449270714\n",
            "tmax_2m5_1 ,  tmp_sfc2_1  :  0.9628057126866638\n",
            "tmax_2m5_1 ,  tmp_sfc3_1  :  0.9789886970467229\n",
            "tmax_2m5_1 ,  tmp_sfc4_1  :  0.9856112141353488\n",
            "tmax_2m5_1 ,  tmp_sfc5_1  :  0.9749315637251419\n",
            "tmax_2m5_1 ,  ulwrf_s3_1  :  0.9665344570534807\n",
            "tmax_2m5_1 ,  ulwrf_s4_1  :  0.9810623570276584\n",
            "tmax_2m5_1 ,  ulwrf_s5_1  :  0.984200309861663\n",
            "tmin_2m1_1 ,  tmin_2m2_1  :  0.9970453886385309\n",
            "tmin_2m1_1 ,  tmin_2m3_1  :  0.9967256583046243\n",
            "tmin_2m1_1 ,  tmp_2m_1_1  :  0.998900820265764\n",
            "tmin_2m1_1 ,  tmp_2m_2_1  :  0.9796606234192073\n",
            "tmin_2m1_1 ,  tmp_2m_3_1  :  0.9518542219855283\n",
            "tmin_2m1_1 ,  tmp_sfc1_1  :  0.9957322491109326\n",
            "tmin_2m1_1 ,  tmp_sfc2_1  :  0.9636513426139934\n",
            "tmin_2m1_1 ,  ulwrf_s1_1  :  0.9930103631464741\n",
            "tmin_2m1_1 ,  ulwrf_s2_1  :  0.9830734818308847\n",
            "tmin_2m1_1 ,  ulwrf_s3_1  :  0.9669978440724937\n",
            "tmin_2m2_1 ,  tmin_2m3_1  :  0.9999115519778132\n",
            "tmin_2m2_1 ,  tmin_2m4_1  :  0.9564185823019342\n",
            "tmin_2m2_1 ,  tmp_2m_1_1  :  0.9984565815420816\n",
            "tmin_2m2_1 ,  tmp_2m_2_1  :  0.985442492553938\n",
            "tmin_2m2_1 ,  tmp_2m_3_1  :  0.9595063058203509\n",
            "tmin_2m2_1 ,  tmp_sfc1_1  :  0.9951955535762588\n",
            "tmin_2m2_1 ,  tmp_sfc2_1  :  0.9700486321043892\n",
            "tmin_2m2_1 ,  ulwrf_s1_1  :  0.9886969444514435\n",
            "tmin_2m2_1 ,  ulwrf_s2_1  :  0.9879101310545606\n",
            "tmin_2m2_1 ,  ulwrf_s3_1  :  0.9729560097445457\n",
            "tmin_2m3_1 ,  tmin_2m4_1  :  0.9574516636355005\n",
            "tmin_2m3_1 ,  tmp_2m_1_1  :  0.9981165089440885\n",
            "tmin_2m3_1 ,  tmp_2m_2_1  :  0.9857209111196503\n",
            "tmin_2m3_1 ,  tmp_2m_3_1  :  0.9604726454407568\n",
            "tmin_2m3_1 ,  tmp_sfc1_1  :  0.9947707412846636\n",
            "tmin_2m3_1 ,  tmp_sfc2_1  :  0.9703992425913751\n",
            "tmin_2m3_1 ,  ulwrf_s1_1  :  0.9883110930292855\n",
            "tmin_2m3_1 ,  ulwrf_s2_1  :  0.9878400001933759\n",
            "tmin_2m3_1 ,  ulwrf_s3_1  :  0.9733940467349225\n",
            "tmin_2m4_1 ,  tmin_2m5_1  :  0.9911267936033283\n",
            "tmin_2m4_1 ,  tmp_2m_2_1  :  0.9835213848148546\n",
            "tmin_2m4_1 ,  tmp_2m_3_1  :  0.9993742471589702\n",
            "tmin_2m4_1 ,  tmp_2m_4_1  :  0.9943422078769039\n",
            "tmin_2m4_1 ,  tmp_2m_5_1  :  0.9819734099052692\n",
            "tmin_2m4_1 ,  tmp_sfc2_1  :  0.9754215350913839\n",
            "tmin_2m4_1 ,  tmp_sfc3_1  :  0.982489319858658\n",
            "tmin_2m4_1 ,  tmp_sfc4_1  :  0.9793188267492576\n",
            "tmin_2m4_1 ,  tmp_sfc5_1  :  0.9717899319272214\n",
            "tmin_2m4_1 ,  ulwrf_s2_1  :  0.9577696807840057\n",
            "tmin_2m4_1 ,  ulwrf_s3_1  :  0.9787999594412927\n",
            "tmin_2m4_1 ,  ulwrf_s4_1  :  0.980143449620344\n",
            "tmin_2m4_1 ,  ulwrf_s5_1  :  0.9813771133745596\n",
            "tmin_2m5_1 ,  tmp_2m_2_1  :  0.9768096456462427\n",
            "tmin_2m5_1 ,  tmp_2m_3_1  :  0.9893370688323362\n",
            "tmin_2m5_1 ,  tmp_2m_4_1  :  0.9908772850680976\n",
            "tmin_2m5_1 ,  tmp_2m_5_1  :  0.9960334550240626\n",
            "tmin_2m5_1 ,  tmp_sfc2_1  :  0.9757894398550752\n",
            "tmin_2m5_1 ,  tmp_sfc3_1  :  0.9788575295460246\n",
            "tmin_2m5_1 ,  tmp_sfc4_1  :  0.9835105827516376\n",
            "tmin_2m5_1 ,  tmp_sfc5_1  :  0.9902872074811198\n",
            "tmin_2m5_1 ,  ulwrf_s2_1  :  0.9589857082323566\n",
            "tmin_2m5_1 ,  ulwrf_s3_1  :  0.9784901467524176\n",
            "tmin_2m5_1 ,  ulwrf_s4_1  :  0.9811321018008656\n",
            "tmin_2m5_1 ,  ulwrf_s5_1  :  0.9880540117657044\n",
            "tmp_2m_1_1 ,  tmp_2m_2_1  :  0.9805563096737225\n",
            "tmp_2m_1_1 ,  tmp_2m_3_1  :  0.9529801008571053\n",
            "tmp_2m_1_1 ,  tmp_sfc1_1  :  0.9964812699160899\n",
            "tmp_2m_1_1 ,  tmp_sfc2_1  :  0.9636845126631818\n",
            "tmp_2m_1_1 ,  ulwrf_s1_1  :  0.9913538257824956\n",
            "tmp_2m_1_1 ,  ulwrf_s2_1  :  0.9839163859252648\n",
            "tmp_2m_1_1 ,  ulwrf_s3_1  :  0.9672743168787754\n",
            "tmp_2m_2_1 ,  tmp_2m_3_1  :  0.9859406728253164\n",
            "tmp_2m_2_1 ,  tmp_2m_4_1  :  0.9670012406532359\n",
            "tmp_2m_2_1 ,  tmp_2m_5_1  :  0.9672062271039558\n",
            "tmp_2m_2_1 ,  tmp_sfc1_1  :  0.971562193636495\n",
            "tmp_2m_2_1 ,  tmp_sfc2_1  :  0.9927554012444447\n",
            "tmp_2m_2_1 ,  tmp_sfc3_1  :  0.9631525425367369\n",
            "tmp_2m_2_1 ,  tmp_sfc4_1  :  0.9534301924023092\n",
            "tmp_2m_2_1 ,  tmp_sfc5_1  :  0.9673874181562205\n",
            "tmp_2m_2_1 ,  ulwrf_s1_1  :  0.9683054750306163\n",
            "tmp_2m_2_1 ,  ulwrf_s2_1  :  0.9881797788608879\n",
            "tmp_2m_2_1 ,  ulwrf_s3_1  :  0.9915806558896973\n",
            "tmp_2m_2_1 ,  ulwrf_s4_1  :  0.9576129609159796\n",
            "tmp_2m_2_1 ,  ulwrf_s5_1  :  0.9624204861962447\n",
            "tmp_2m_3_1 ,  tmp_2m_4_1  :  0.9921027644203689\n",
            "tmp_2m_3_1 ,  tmp_2m_5_1  :  0.9797121777392374\n",
            "tmp_2m_3_1 ,  tmp_sfc2_1  :  0.9775476247187543\n",
            "tmp_2m_3_1 ,  tmp_sfc3_1  :  0.9820691886560374\n",
            "tmp_2m_3_1 ,  tmp_sfc4_1  :  0.9763383022408996\n",
            "tmp_2m_3_1 ,  tmp_sfc5_1  :  0.9703429486336607\n",
            "tmp_2m_3_1 ,  ulwrf_s2_1  :  0.9604204438375086\n",
            "tmp_2m_3_1 ,  ulwrf_s3_1  :  0.9804938202794544\n",
            "tmp_2m_3_1 ,  ulwrf_s4_1  :  0.9782153624560592\n",
            "tmp_2m_3_1 ,  ulwrf_s5_1  :  0.9791932701810832\n",
            "tmp_2m_4_1 ,  tmp_2m_5_1  :  0.9875528601203459\n",
            "tmp_2m_4_1 ,  tmp_sfc2_1  :  0.960624422657449\n",
            "tmp_2m_4_1 ,  tmp_sfc3_1  :  0.9792770660192405\n",
            "tmp_2m_4_1 ,  tmp_sfc4_1  :  0.9869090259085422\n",
            "tmp_2m_4_1 ,  tmp_sfc5_1  :  0.9738272150206101\n",
            "tmp_2m_4_1 ,  ulwrf_s3_1  :  0.9649262558395967\n",
            "tmp_2m_4_1 ,  ulwrf_s4_1  :  0.9821817415867544\n",
            "tmp_2m_4_1 ,  ulwrf_s5_1  :  0.9849565672923875\n",
            "tmp_2m_5_1 ,  tmp_sfc2_1  :  0.9697643332491326\n",
            "tmp_2m_5_1 ,  tmp_sfc3_1  :  0.9724836017385601\n",
            "tmp_2m_5_1 ,  tmp_sfc4_1  :  0.9843139991815588\n",
            "tmp_2m_5_1 ,  tmp_sfc5_1  :  0.9959415103906808\n",
            "tmp_2m_5_1 ,  ulwrf_s2_1  :  0.9528681615510463\n",
            "tmp_2m_5_1 ,  ulwrf_s3_1  :  0.9716219042552314\n",
            "tmp_2m_5_1 ,  ulwrf_s4_1  :  0.9781031046024419\n",
            "tmp_2m_5_1 ,  ulwrf_s5_1  :  0.9881965240907419\n",
            "tmp_sfc1_1 ,  tmp_sfc2_1  :  0.9589725251963025\n",
            "tmp_sfc1_1 ,  ulwrf_s1_1  :  0.9945207077467407\n",
            "tmp_sfc1_1 ,  ulwrf_s2_1  :  0.9851346861013133\n",
            "tmp_sfc1_1 ,  ulwrf_s3_1  :  0.9622951827455389\n",
            "tmp_sfc2_1 ,  tmp_sfc3_1  :  0.9715012456822736\n",
            "tmp_sfc2_1 ,  tmp_sfc4_1  :  0.9601110377479757\n",
            "tmp_sfc2_1 ,  tmp_sfc5_1  :  0.9758427242385672\n",
            "tmp_sfc2_1 ,  ulwrf_s1_1  :  0.9584319747371385\n",
            "tmp_sfc2_1 ,  ulwrf_s2_1  :  0.9883597139532562\n",
            "tmp_sfc2_1 ,  ulwrf_s3_1  :  0.996629047383539\n",
            "tmp_sfc2_1 ,  ulwrf_s4_1  :  0.9655179833343889\n",
            "tmp_sfc2_1 ,  ulwrf_s5_1  :  0.9703306321964995\n",
            "tmp_sfc3_1 ,  tmp_sfc4_1  :  0.989522193314478\n",
            "tmp_sfc3_1 ,  tmp_sfc5_1  :  0.9678004146767386\n",
            "tmp_sfc3_1 ,  ulwrf_s3_1  :  0.9766856429075442\n",
            "tmp_sfc3_1 ,  ulwrf_s4_1  :  0.9954450239499772\n",
            "tmp_sfc3_1 ,  ulwrf_s5_1  :  0.9908158435871326\n",
            "tmp_sfc4_1 ,  tmp_sfc5_1  :  0.9779131037432472\n",
            "tmp_sfc4_1 ,  ulwrf_s3_1  :  0.9655105552160815\n",
            "tmp_sfc4_1 ,  ulwrf_s4_1  :  0.9957715925666815\n",
            "tmp_sfc4_1 ,  ulwrf_s5_1  :  0.9967247736731752\n",
            "tmp_sfc5_1 ,  ulwrf_s2_1  :  0.9620709877849453\n",
            "tmp_sfc5_1 ,  ulwrf_s3_1  :  0.9763289741407619\n",
            "tmp_sfc5_1 ,  ulwrf_s4_1  :  0.9732079153686789\n",
            "tmp_sfc5_1 ,  ulwrf_s5_1  :  0.9852418909120759\n",
            "ulwrf_s1_1 ,  ulwrf_s2_1  :  0.9835448558639645\n",
            "ulwrf_s1_1 ,  ulwrf_s3_1  :  0.9640577336673629\n",
            "ulwrf_s2_1 ,  ulwrf_s3_1  :  0.9906687347164609\n",
            "ulwrf_s3_1 ,  ulwrf_s4_1  :  0.9738347421405523\n",
            "ulwrf_s3_1 ,  ulwrf_s5_1  :  0.9772971100975745\n",
            "ulwrf_s4_1 ,  ulwrf_s5_1  :  0.9976091460627659\n",
            "ulwrf_t2_1 ,  ulwrf_t3_1  :  0.9770930160651596\n",
            "ulwrf_t4_1 ,  ulwrf_t5_1  :  0.9797534221599368\n",
            "uswrf_s4_1 ,  uswrf_s5_1  :  0.955842759863491\n",
            "[['dlwrf_s1_1', 'dlwrf_s2_1'], ['dlwrf_s1_1', 'dlwrf_s3_1'], ['dlwrf_s2_1', 'dlwrf_s3_1'], ['dlwrf_s3_1', 'dlwrf_s4_1'], ['dlwrf_s3_1', 'dlwrf_s5_1'], ['dlwrf_s4_1', 'dlwrf_s5_1'], ['dswrf_s2_1', 'dswrf_s3_1'], ['dswrf_s2_1', 'uswrf_s2_1'], ['dswrf_s3_1', 'uswrf_s2_1'], ['dswrf_s3_1', 'uswrf_s3_1'], ['dswrf_s4_1', 'dswrf_s5_1'], ['pres_ms1_1', 'pres_ms2_1'], ['pres_ms1_1', 'pres_ms3_1'], ['pres_ms2_1', 'pres_ms3_1'], ['pres_ms3_1', 'pres_ms4_1'], ['pres_ms3_1', 'pres_ms5_1'], ['pres_ms4_1', 'pres_ms5_1'], ['pwat_ea1_1', 'pwat_ea2_1'], ['pwat_ea1_1', 'pwat_ea3_1'], ['pwat_ea2_1', 'pwat_ea3_1'], ['pwat_ea2_1', 'pwat_ea4_1'], ['pwat_ea3_1', 'pwat_ea4_1'], ['pwat_ea3_1', 'pwat_ea5_1'], ['pwat_ea4_1', 'pwat_ea5_1'], ['spfh_2m1_1', 'spfh_2m2_1'], ['spfh_2m2_1', 'spfh_2m3_1'], ['spfh_2m3_1', 'spfh_2m4_1'], ['spfh_2m3_1', 'spfh_2m5_1'], ['spfh_2m4_1', 'spfh_2m5_1'], ['tcdc_ea1_1', 'tcolc_e1_1'], ['tcdc_ea2_1', 'tcolc_e2_1'], ['tcdc_ea3_1', 'tcolc_e3_1'], ['tcdc_ea4_1', 'tcolc_e4_1'], ['tcdc_ea5_1', 'tcolc_e5_1'], ['tmax_2m1_1', 'tmax_2m2_1'], ['tmax_2m1_1', 'tmin_2m1_1'], ['tmax_2m1_1', 'tmin_2m2_1'], ['tmax_2m1_1', 'tmin_2m3_1'], ['tmax_2m1_1', 'tmp_2m_1_1'], ['tmax_2m1_1', 'tmp_2m_2_1'], ['tmax_2m1_1', 'tmp_sfc1_1'], ['tmax_2m1_1', 'tmp_sfc2_1'], ['tmax_2m1_1', 'ulwrf_s1_1'], ['tmax_2m1_1', 'ulwrf_s2_1'], ['tmax_2m1_1', 'ulwrf_s3_1'], ['tmax_2m2_1', 'tmax_2m3_1'], ['tmax_2m2_1', 'tmax_2m4_1'], ['tmax_2m2_1', 'tmax_2m5_1'], ['tmax_2m2_1', 'tmin_2m1_1'], ['tmax_2m2_1', 'tmin_2m2_1'], ['tmax_2m2_1', 'tmin_2m3_1'], ['tmax_2m2_1', 'tmin_2m4_1'], ['tmax_2m2_1', 'tmin_2m5_1'], ['tmax_2m2_1', 'tmp_2m_1_1'], ['tmax_2m2_1', 'tmp_2m_2_1'], ['tmax_2m2_1', 'tmp_2m_3_1'], ['tmax_2m2_1', 'tmp_2m_4_1'], ['tmax_2m2_1', 'tmp_2m_5_1'], ['tmax_2m2_1', 'tmp_sfc1_1'], ['tmax_2m2_1', 'tmp_sfc2_1'], ['tmax_2m2_1', 'tmp_sfc3_1'], ['tmax_2m2_1', 'tmp_sfc4_1'], ['tmax_2m2_1', 'tmp_sfc5_1'], ['tmax_2m2_1', 'ulwrf_s1_1'], ['tmax_2m2_1', 'ulwrf_s2_1'], ['tmax_2m2_1', 'ulwrf_s3_1'], ['tmax_2m2_1', 'ulwrf_s4_1'], ['tmax_2m2_1', 'ulwrf_s5_1'], ['tmax_2m3_1', 'tmax_2m4_1'], ['tmax_2m3_1', 'tmax_2m5_1'], ['tmax_2m3_1', 'tmin_2m1_1'], ['tmax_2m3_1', 'tmin_2m2_1'], ['tmax_2m3_1', 'tmin_2m3_1'], ['tmax_2m3_1', 'tmin_2m4_1'], ['tmax_2m3_1', 'tmin_2m5_1'], ['tmax_2m3_1', 'tmp_2m_1_1'], ['tmax_2m3_1', 'tmp_2m_2_1'], ['tmax_2m3_1', 'tmp_2m_3_1'], ['tmax_2m3_1', 'tmp_2m_4_1'], ['tmax_2m3_1', 'tmp_2m_5_1'], ['tmax_2m3_1', 'tmp_sfc2_1'], ['tmax_2m3_1', 'tmp_sfc3_1'], ['tmax_2m3_1', 'tmp_sfc4_1'], ['tmax_2m3_1', 'tmp_sfc5_1'], ['tmax_2m3_1', 'ulwrf_s2_1'], ['tmax_2m3_1', 'ulwrf_s3_1'], ['tmax_2m3_1', 'ulwrf_s4_1'], ['tmax_2m3_1', 'ulwrf_s5_1'], ['tmax_2m4_1', 'tmax_2m5_1'], ['tmax_2m4_1', 'tmin_2m4_1'], ['tmax_2m4_1', 'tmin_2m5_1'], ['tmax_2m4_1', 'tmp_2m_2_1'], ['tmax_2m4_1', 'tmp_2m_3_1'], ['tmax_2m4_1', 'tmp_2m_4_1'], ['tmax_2m4_1', 'tmp_2m_5_1'], ['tmax_2m4_1', 'tmp_sfc2_1'], ['tmax_2m4_1', 'tmp_sfc3_1'], ['tmax_2m4_1', 'tmp_sfc4_1'], ['tmax_2m4_1', 'tmp_sfc5_1'], ['tmax_2m4_1', 'ulwrf_s3_1'], ['tmax_2m4_1', 'ulwrf_s4_1'], ['tmax_2m4_1', 'ulwrf_s5_1'], ['tmax_2m5_1', 'tmin_2m4_1'], ['tmax_2m5_1', 'tmin_2m5_1'], ['tmax_2m5_1', 'tmp_2m_2_1'], ['tmax_2m5_1', 'tmp_2m_3_1'], ['tmax_2m5_1', 'tmp_2m_4_1'], ['tmax_2m5_1', 'tmp_2m_5_1'], ['tmax_2m5_1', 'tmp_sfc2_1'], ['tmax_2m5_1', 'tmp_sfc3_1'], ['tmax_2m5_1', 'tmp_sfc4_1'], ['tmax_2m5_1', 'tmp_sfc5_1'], ['tmax_2m5_1', 'ulwrf_s3_1'], ['tmax_2m5_1', 'ulwrf_s4_1'], ['tmax_2m5_1', 'ulwrf_s5_1'], ['tmin_2m1_1', 'tmin_2m2_1'], ['tmin_2m1_1', 'tmin_2m3_1'], ['tmin_2m1_1', 'tmp_2m_1_1'], ['tmin_2m1_1', 'tmp_2m_2_1'], ['tmin_2m1_1', 'tmp_2m_3_1'], ['tmin_2m1_1', 'tmp_sfc1_1'], ['tmin_2m1_1', 'tmp_sfc2_1'], ['tmin_2m1_1', 'ulwrf_s1_1'], ['tmin_2m1_1', 'ulwrf_s2_1'], ['tmin_2m1_1', 'ulwrf_s3_1'], ['tmin_2m2_1', 'tmin_2m3_1'], ['tmin_2m2_1', 'tmin_2m4_1'], ['tmin_2m2_1', 'tmp_2m_1_1'], ['tmin_2m2_1', 'tmp_2m_2_1'], ['tmin_2m2_1', 'tmp_2m_3_1'], ['tmin_2m2_1', 'tmp_sfc1_1'], ['tmin_2m2_1', 'tmp_sfc2_1'], ['tmin_2m2_1', 'ulwrf_s1_1'], ['tmin_2m2_1', 'ulwrf_s2_1'], ['tmin_2m2_1', 'ulwrf_s3_1'], ['tmin_2m3_1', 'tmin_2m4_1'], ['tmin_2m3_1', 'tmp_2m_1_1'], ['tmin_2m3_1', 'tmp_2m_2_1'], ['tmin_2m3_1', 'tmp_2m_3_1'], ['tmin_2m3_1', 'tmp_sfc1_1'], ['tmin_2m3_1', 'tmp_sfc2_1'], ['tmin_2m3_1', 'ulwrf_s1_1'], ['tmin_2m3_1', 'ulwrf_s2_1'], ['tmin_2m3_1', 'ulwrf_s3_1'], ['tmin_2m4_1', 'tmin_2m5_1'], ['tmin_2m4_1', 'tmp_2m_2_1'], ['tmin_2m4_1', 'tmp_2m_3_1'], ['tmin_2m4_1', 'tmp_2m_4_1'], ['tmin_2m4_1', 'tmp_2m_5_1'], ['tmin_2m4_1', 'tmp_sfc2_1'], ['tmin_2m4_1', 'tmp_sfc3_1'], ['tmin_2m4_1', 'tmp_sfc4_1'], ['tmin_2m4_1', 'tmp_sfc5_1'], ['tmin_2m4_1', 'ulwrf_s2_1'], ['tmin_2m4_1', 'ulwrf_s3_1'], ['tmin_2m4_1', 'ulwrf_s4_1'], ['tmin_2m4_1', 'ulwrf_s5_1'], ['tmin_2m5_1', 'tmp_2m_2_1'], ['tmin_2m5_1', 'tmp_2m_3_1'], ['tmin_2m5_1', 'tmp_2m_4_1'], ['tmin_2m5_1', 'tmp_2m_5_1'], ['tmin_2m5_1', 'tmp_sfc2_1'], ['tmin_2m5_1', 'tmp_sfc3_1'], ['tmin_2m5_1', 'tmp_sfc4_1'], ['tmin_2m5_1', 'tmp_sfc5_1'], ['tmin_2m5_1', 'ulwrf_s2_1'], ['tmin_2m5_1', 'ulwrf_s3_1'], ['tmin_2m5_1', 'ulwrf_s4_1'], ['tmin_2m5_1', 'ulwrf_s5_1'], ['tmp_2m_1_1', 'tmp_2m_2_1'], ['tmp_2m_1_1', 'tmp_2m_3_1'], ['tmp_2m_1_1', 'tmp_sfc1_1'], ['tmp_2m_1_1', 'tmp_sfc2_1'], ['tmp_2m_1_1', 'ulwrf_s1_1'], ['tmp_2m_1_1', 'ulwrf_s2_1'], ['tmp_2m_1_1', 'ulwrf_s3_1'], ['tmp_2m_2_1', 'tmp_2m_3_1'], ['tmp_2m_2_1', 'tmp_2m_4_1'], ['tmp_2m_2_1', 'tmp_2m_5_1'], ['tmp_2m_2_1', 'tmp_sfc1_1'], ['tmp_2m_2_1', 'tmp_sfc2_1'], ['tmp_2m_2_1', 'tmp_sfc3_1'], ['tmp_2m_2_1', 'tmp_sfc4_1'], ['tmp_2m_2_1', 'tmp_sfc5_1'], ['tmp_2m_2_1', 'ulwrf_s1_1'], ['tmp_2m_2_1', 'ulwrf_s2_1'], ['tmp_2m_2_1', 'ulwrf_s3_1'], ['tmp_2m_2_1', 'ulwrf_s4_1'], ['tmp_2m_2_1', 'ulwrf_s5_1'], ['tmp_2m_3_1', 'tmp_2m_4_1'], ['tmp_2m_3_1', 'tmp_2m_5_1'], ['tmp_2m_3_1', 'tmp_sfc2_1'], ['tmp_2m_3_1', 'tmp_sfc3_1'], ['tmp_2m_3_1', 'tmp_sfc4_1'], ['tmp_2m_3_1', 'tmp_sfc5_1'], ['tmp_2m_3_1', 'ulwrf_s2_1'], ['tmp_2m_3_1', 'ulwrf_s3_1'], ['tmp_2m_3_1', 'ulwrf_s4_1'], ['tmp_2m_3_1', 'ulwrf_s5_1'], ['tmp_2m_4_1', 'tmp_2m_5_1'], ['tmp_2m_4_1', 'tmp_sfc2_1'], ['tmp_2m_4_1', 'tmp_sfc3_1'], ['tmp_2m_4_1', 'tmp_sfc4_1'], ['tmp_2m_4_1', 'tmp_sfc5_1'], ['tmp_2m_4_1', 'ulwrf_s3_1'], ['tmp_2m_4_1', 'ulwrf_s4_1'], ['tmp_2m_4_1', 'ulwrf_s5_1'], ['tmp_2m_5_1', 'tmp_sfc2_1'], ['tmp_2m_5_1', 'tmp_sfc3_1'], ['tmp_2m_5_1', 'tmp_sfc4_1'], ['tmp_2m_5_1', 'tmp_sfc5_1'], ['tmp_2m_5_1', 'ulwrf_s2_1'], ['tmp_2m_5_1', 'ulwrf_s3_1'], ['tmp_2m_5_1', 'ulwrf_s4_1'], ['tmp_2m_5_1', 'ulwrf_s5_1'], ['tmp_sfc1_1', 'tmp_sfc2_1'], ['tmp_sfc1_1', 'ulwrf_s1_1'], ['tmp_sfc1_1', 'ulwrf_s2_1'], ['tmp_sfc1_1', 'ulwrf_s3_1'], ['tmp_sfc2_1', 'tmp_sfc3_1'], ['tmp_sfc2_1', 'tmp_sfc4_1'], ['tmp_sfc2_1', 'tmp_sfc5_1'], ['tmp_sfc2_1', 'ulwrf_s1_1'], ['tmp_sfc2_1', 'ulwrf_s2_1'], ['tmp_sfc2_1', 'ulwrf_s3_1'], ['tmp_sfc2_1', 'ulwrf_s4_1'], ['tmp_sfc2_1', 'ulwrf_s5_1'], ['tmp_sfc3_1', 'tmp_sfc4_1'], ['tmp_sfc3_1', 'tmp_sfc5_1'], ['tmp_sfc3_1', 'ulwrf_s3_1'], ['tmp_sfc3_1', 'ulwrf_s4_1'], ['tmp_sfc3_1', 'ulwrf_s5_1'], ['tmp_sfc4_1', 'tmp_sfc5_1'], ['tmp_sfc4_1', 'ulwrf_s3_1'], ['tmp_sfc4_1', 'ulwrf_s4_1'], ['tmp_sfc4_1', 'ulwrf_s5_1'], ['tmp_sfc5_1', 'ulwrf_s2_1'], ['tmp_sfc5_1', 'ulwrf_s3_1'], ['tmp_sfc5_1', 'ulwrf_s4_1'], ['tmp_sfc5_1', 'ulwrf_s5_1'], ['ulwrf_s1_1', 'ulwrf_s2_1'], ['ulwrf_s1_1', 'ulwrf_s3_1'], ['ulwrf_s2_1', 'ulwrf_s3_1'], ['ulwrf_s3_1', 'ulwrf_s4_1'], ['ulwrf_s3_1', 'ulwrf_s5_1'], ['ulwrf_s4_1', 'ulwrf_s5_1'], ['ulwrf_t2_1', 'ulwrf_t3_1'], ['ulwrf_t4_1', 'ulwrf_t5_1'], ['uswrf_s4_1', 'uswrf_s5_1']]\n"
          ]
        }
      ],
      "source": [
        "list=[]\n",
        "for i in disp_df:\n",
        "  for k in disp_df:\n",
        "    \"\"\"print(disp_df[i].corr(disp_df[k]))\"\"\"\n",
        "    #Esto nos sirve para saber que 1 es el máximo\n",
        "    if i!=k and not -0.95<=disp_df[i].corr(disp_df[k])<=0.95 and i!=\"uswrf_s1_1\" and k!=\"uswrf_s1_1\":\n",
        "      if [i,k] not in list and [k,i] not in list:\n",
        "        list.append([i,k])\n",
        "        print(i,\", \",k,\" : \",disp_df[i].corr(disp_df[k]))\n",
        "      \n",
        "print(list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS_yHaYX7443"
      },
      "source": [
        "En list tenemos todas las columnas altamente correlacionadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "odeG4E4HTrNl"
      },
      "outputs": [],
      "source": [
        "#display(disp_df)\n",
        "import numpy as np\n",
        "from numpy.lib.function_base import disp\n",
        "import pandas as pd\n",
        "for i in disp_df:\n",
        "  for k in range(len(disp_df[i])):\n",
        "    if disp_df[i][k]==np.nan:\n",
        "      print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo6yQRiY4EE_"
      },
      "source": [
        "####Normalizamos los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVUElA1sUgpq",
        "outputId": "4d6d5999-afb7-456d-b652-3c02beb721e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apcp_sf1_1 35.34527131609055\n",
            "apcp_sf2_1 66.53638839905511\n",
            "apcp_sf3_1 53.13619594585077\n",
            "apcp_sf4_1 0.6902865527001909\n",
            "apcp_sf5_1 388.61446765566023\n",
            "dlwrf_s1_1 0.5690586015004552\n",
            "dlwrf_s2_1 0.5604280980745557\n",
            "dlwrf_s3_1 0.5599100960180365\n",
            "dlwrf_s4_1 0.5547244234757622\n",
            "dlwrf_s5_1 0.5511972663349181\n",
            "dswrf_s1_1 0.11261614127640085\n",
            "dswrf_s2_1 0.5244378685307185\n",
            "dswrf_s3_1 0.542719374275947\n",
            "dswrf_s4_1 0.5831412440294939\n",
            "dswrf_s5_1 0.5448927304212977\n",
            "pres_ms1_1 0.8013205554909132\n",
            "pres_ms2_1 0.8000760839594527\n",
            "pres_ms3_1 0.8045473701643405\n",
            "pres_ms4_1 0.8150731212020463\n",
            "pres_ms5_1 0.8075559976191413\n",
            "pwat_ea1_1 0.6082063140958146\n",
            "pwat_ea2_1 0.6072553678220067\n",
            "pwat_ea3_1 0.6039178374017136\n",
            "pwat_ea4_1 0.5997911606743963\n",
            "pwat_ea5_1 0.5956526216702805\n",
            "spfh_2m1_1 0.5815653017261748\n",
            "spfh_2m2_1 0.5690428651413918\n",
            "spfh_2m3_1 0.5708540110551112\n",
            "spfh_2m4_1 0.5792918254933966\n",
            "spfh_2m5_1 0.5772227939267285\n",
            "tcdc_ea1_1 3.7599959314426297\n",
            "tcdc_ea2_1 4.285342587457867\n",
            "tcdc_ea3_1 5.05894175114318\n",
            "tcdc_ea4_1 4.821137464945439\n",
            "tcdc_ea5_1 4.903920088224773\n",
            "tcolc_e1_1 3.7582154909742007\n",
            "tcolc_e2_1 4.351134971957474\n",
            "tcolc_e3_1 5.018297839228021\n",
            "tcolc_e4_1 4.772803484115125\n",
            "tcolc_e5_1 4.972573440882263\n",
            "tmax_2m1_1 0.6027942193532075\n",
            "tmax_2m2_1 0.5850690273645633\n",
            "tmax_2m3_1 0.6019119056032652\n",
            "tmax_2m4_1 0.6078854088921363\n",
            "tmax_2m5_1 0.6078615939160603\n",
            "tmin_2m1_1 0.5951943040636267\n",
            "tmin_2m2_1 0.5867972506008845\n",
            "tmin_2m3_1 0.5868100046066427\n",
            "tmin_2m4_1 0.6046806851033302\n",
            "tmin_2m5_1 0.5897375912185668\n",
            "tmp_2m_1_1 0.5934683254670114\n",
            "tmp_2m_2_1 0.5828202537168462\n",
            "tmp_2m_3_1 0.6044941370795561\n",
            "tmp_2m_4_1 0.6047926493636394\n",
            "tmp_2m_5_1 0.5822375824988294\n",
            "tmp_sfc1_1 0.5847349929743803\n",
            "tmp_sfc2_1 0.5635451696162402\n",
            "tmp_sfc3_1 0.5899302801392245\n",
            "tmp_sfc4_1 0.6037425416567633\n",
            "tmp_sfc5_1 0.570286717658704\n",
            "ulwrf_s1_1 0.5853670792796786\n",
            "ulwrf_s2_1 0.5559291423668461\n",
            "ulwrf_s3_1 0.5639857595010687\n",
            "ulwrf_s4_1 0.5883386329269192\n",
            "ulwrf_s5_1 0.5830169842584807\n",
            "ulwrf_t1_1 0.8002761894942011\n",
            "ulwrf_t2_1 0.8055532090176821\n",
            "ulwrf_t3_1 0.8059191299535909\n",
            "ulwrf_t4_1 0.8553741462522099\n",
            "ulwrf_t5_1 0.8224066678625738\n",
            "uswrf_s1_1 0.0\n",
            "uswrf_s2_1 0.5358266136997545\n",
            "uswrf_s3_1 0.5977944808989082\n",
            "uswrf_s4_1 0.7720242658384443\n",
            "uswrf_s5_1 0.6133313632614643\n",
            "salida 0.6244529673772358\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "pd.set_option('display.max_rows', None)\n",
        "#display(disp_df.var())\n",
        "X=disp_df.values\n",
        "robust = RobustScaler()\n",
        "scaled_values = robust.fit_transform(X)\n",
        "scaled_matrix = pd.DataFrame(scaled_values)\n",
        "#Creemos que necesitamos hacer la normalización más adelante y al splited data\n",
        "index = 0\n",
        "for i in disp_df:\n",
        "  print(i, scaled_matrix[index].std())\n",
        "  index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "xTXeGW5T9WD9",
        "outputId": "387f0173-d079-4175-9c2f-67151e42ab7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-5e3f291a3ca6>:3: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  seaborn.distplot(disp_df[\"apcp_sf5_1\"])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='apcp_sf5_1', ylabel='Density'>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn\n",
        "\n",
        "seaborn.distplot(disp_df[\"apcp_sf5_1\"])\n",
        "#seaborn.distplot(scaled_matrix[4])\n",
        "#seaborn.boxplot(scaled_matrix[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRY8EXfG8VHy"
      },
      "source": [
        "###Comprobamos la correlación con la salida\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5whCusbJYwuX",
        "outputId": "144a8295-a83e-4f08-a2e8-c29267e72027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correlación salida con  apcp_sf1_1 -0.16213021417225146\n",
            "correlación salida con  apcp_sf2_1 -0.22693195305515088\n",
            "correlación salida con  apcp_sf3_1 -0.25482657684032034\n",
            "correlación salida con  apcp_sf4_1 -0.24638359175743108\n",
            "correlación salida con  apcp_sf5_1 -0.251709690802096\n",
            "correlación salida con  dlwrf_s1_1 0.36538671151738716\n",
            "correlación salida con  dlwrf_s2_1 0.3324084177854513\n",
            "correlación salida con  dlwrf_s3_1 0.37153024058007206\n",
            "correlación salida con  dlwrf_s4_1 0.4618079055814155\n",
            "correlación salida con  dlwrf_s5_1 0.47720762545798917\n",
            "correlación salida con  dswrf_s1_1 0.13360641876924823\n",
            "correlación salida con  dswrf_s2_1 0.8246218105528994\n",
            "correlación salida con  dswrf_s3_1 0.8802982839969848\n",
            "correlación salida con  dswrf_s4_1 0.875697345874555\n",
            "correlación salida con  dswrf_s5_1 0.8773294983106668\n",
            "correlación salida con  pres_ms1_1 -0.2854430805293465\n",
            "correlación salida con  pres_ms2_1 -0.2922649346561904\n",
            "correlación salida con  pres_ms3_1 -0.302003504480284\n",
            "correlación salida con  pres_ms4_1 -0.29854019585317537\n",
            "correlación salida con  pres_ms5_1 -0.34895128753502325\n",
            "correlación salida con  pwat_ea1_1 0.2649960273661967\n",
            "correlación salida con  pwat_ea2_1 0.2538607203733222\n",
            "correlación salida con  pwat_ea3_1 0.2626550619398881\n",
            "correlación salida con  pwat_ea4_1 0.2845613998768444\n",
            "correlación salida con  pwat_ea5_1 0.30585805743804806\n",
            "correlación salida con  spfh_2m1_1 0.36753993696298637\n",
            "correlación salida con  spfh_2m2_1 0.4111992846679255\n",
            "correlación salida con  spfh_2m3_1 0.3975133345518356\n",
            "correlación salida con  spfh_2m4_1 0.35979687610559813\n",
            "correlación salida con  spfh_2m5_1 0.38328316020188824\n",
            "correlación salida con  tcdc_ea1_1 -0.355092422234161\n",
            "correlación salida con  tcdc_ea2_1 -0.4131303187362299\n",
            "correlación salida con  tcdc_ea3_1 -0.4103821138697305\n",
            "correlación salida con  tcdc_ea4_1 -0.40498095356838076\n",
            "correlación salida con  tcdc_ea5_1 -0.33300057489599627\n",
            "correlación salida con  tcolc_e1_1 -0.35475848121990766\n",
            "correlación salida con  tcolc_e2_1 -0.412855853449115\n",
            "correlación salida con  tcolc_e3_1 -0.41002071486001557\n",
            "correlación salida con  tcolc_e4_1 -0.40441312141815783\n",
            "correlación salida con  tcolc_e5_1 -0.33228781535090485\n",
            "correlación salida con  tmax_2m1_1 0.5834702449087105\n",
            "correlación salida con  tmax_2m2_1 0.640528433590476\n",
            "correlación salida con  tmax_2m3_1 0.6840779002936103\n",
            "correlación salida con  tmax_2m4_1 0.6993653289164493\n",
            "correlación salida con  tmax_2m5_1 0.6994089661710121\n",
            "correlación salida con  tmin_2m1_1 0.5589565132701781\n",
            "correlación salida con  tmin_2m2_1 0.5640547389045715\n",
            "correlación salida con  tmin_2m3_1 0.5654278982705099\n",
            "correlación salida con  tmin_2m4_1 0.6909607413292633\n",
            "correlación salida con  tmin_2m5_1 0.7072265162486207\n",
            "correlación salida con  tmp_2m_1_1 0.5560405514918622\n",
            "correlación salida con  tmp_2m_2_1 0.6433943965446033\n",
            "correlación salida con  tmp_2m_3_1 0.6863734776458205\n",
            "correlación salida con  tmp_2m_4_1 0.7040932033853942\n",
            "correlación salida con  tmp_2m_5_1 0.7129421641301222\n",
            "correlación salida con  tmp_sfc1_1 0.5391344008767125\n",
            "correlación salida con  tmp_sfc2_1 0.6762263064641242\n",
            "correlación salida con  tmp_sfc3_1 0.7376008421430015\n",
            "correlación salida con  tmp_sfc4_1 0.7477494663127511\n",
            "correlación salida con  tmp_sfc5_1 0.7124430486393385\n",
            "correlación salida con  ulwrf_s1_1 0.5625573385917527\n",
            "correlación salida con  ulwrf_s2_1 0.6192260026976277\n",
            "correlación salida con  ulwrf_s3_1 0.6787705637243145\n",
            "correlación salida con  ulwrf_s4_1 0.7467637193799265\n",
            "correlación salida con  ulwrf_s5_1 0.7455099018298113\n",
            "correlación salida con  ulwrf_t1_1 0.5339048961042566\n",
            "correlación salida con  ulwrf_t2_1 0.622970574871868\n",
            "correlación salida con  ulwrf_t3_1 0.671692731509569\n",
            "correlación salida con  ulwrf_t4_1 0.6917501946101022\n",
            "correlación salida con  ulwrf_t5_1 0.6952442614419652\n",
            "correlación salida con  uswrf_s1_1 nan\n",
            "correlación salida con  uswrf_s2_1 0.8433543637245977\n",
            "correlación salida con  uswrf_s3_1 0.8642002022026374\n",
            "correlación salida con  uswrf_s4_1 0.7452035228276859\n",
            "correlación salida con  uswrf_s5_1 0.8312765666316183\n",
            "correlación salida con  salida 1.0\n"
          ]
        }
      ],
      "source": [
        "lista_salida=[]\n",
        "for i in disp_df:\n",
        "    print(\"correlación salida con \", i, disp_df[i].corr(disp_df[\"salida\"]))\n",
        "    if disp_df[i].corr(disp_df[\"salida\"])>0.85 or disp_df[i].corr(disp_df[\"salida\"])<-0.85:\n",
        "      lista_salida.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX-tN8az8mbV"
      },
      "source": [
        "## Hipótesis\n",
        "\n",
        "\n",
        "\n",
        "Podemos ver que la columna \"uswrf_s1_1\" es inútil.\n",
        "También tenemos en la variable \"lista\" el array que incluye las combinaciones de variables altamente relacionadas unas con otras. Por último en lista_salida tenemos las columnas altamente correlacionadas con la salida.\n",
        "Hemos decidido por lo cual reducir el dataset quitando la columna inútil, también vamos a minimizar el número de variables.\n",
        "No vamos a borrar las variables con baja correlación con la salida ya que dicha correlación es sólo lineal así que al eliminarla podriamos quitar variables altamente correlacionadas no linearmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "CetuxmLEBxvb",
        "outputId": "19efa10e-0d6c-4e1e-9d8d-896a354974d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'list_elimino =[]\\nlist_dejo=[]\\n\\nfor i in list:\\n  if i[0] not in list_elimino and i[1] not in list_elimino:\\n    #Queremos eliminar si no vamos a eliminar\\n    list_elimino.append(i[0])\\n    disp_df.drop(i[0], axis=1, inplace=True)\\n\\nlist=[]\\nfor i in disp_df:\\n  for k in disp_df:\\n    #print(disp_df[i].corr(disp_df[k]))\\n    #Esto nos sirve para saber que 1 es el máximo\\n    if i!=k and not -0.90<=disp_df[i].corr(disp_df[k])<=0.90 and i!=\"uswrf_s1_1\" and k!=\"uswrf_s1_1\":\\n      if [i,k] not in list and [k,i] not in list:\\n        list.append([i,k])\\n        print(i,\", \",k,\" : \",disp_df[i].corr(disp_df[k]))\\n      \\nprint(list)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "disp_df = disp_df.drop(columns=['uswrf_s1_1'])\n",
        "\"\"\"list_elimino =[]\n",
        "list_dejo=[]\n",
        "\n",
        "for i in list:\n",
        "  if i[0] not in list_elimino and i[1] not in list_elimino:\n",
        "    #Queremos eliminar si no vamos a eliminar\n",
        "    list_elimino.append(i[0])\n",
        "    disp_df.drop(i[0], axis=1, inplace=True)\n",
        "\n",
        "list=[]\n",
        "for i in disp_df:\n",
        "  for k in disp_df:\n",
        "    #print(disp_df[i].corr(disp_df[k]))\n",
        "    #Esto nos sirve para saber que 1 es el máximo\n",
        "    if i!=k and not -0.90<=disp_df[i].corr(disp_df[k])<=0.90 and i!=\"uswrf_s1_1\" and k!=\"uswrf_s1_1\":\n",
        "      if [i,k] not in list and [k,i] not in list:\n",
        "        list.append([i,k])\n",
        "        print(i,\", \",k,\" : \",disp_df[i].corr(disp_df[k]))\n",
        "      \n",
        "print(list)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XwgqVoL5_uy"
      },
      "source": [
        "# Métodos básicos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tLX0ahI900y"
      },
      "source": [
        "Definición de las variables básicas: X, y, X_train, X_test, y_train e y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh-a4BhF9dGT",
        "outputId": "b4ded5e0-25e7-4d4c-b805-ddb776736a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    4.380000e+03\n",
            "mean     1.807402e+07\n",
            "std      7.898549e+06\n",
            "min      3.291000e+05\n",
            "25%      1.240575e+07\n",
            "50%      1.825620e+07\n",
            "75%      2.505450e+07\n",
            "max      3.232680e+07\n",
            "Name: salida, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = disp_df.loc[:, disp_df.columns != 'salida']\n",
        "y = disp_df[\"salida\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=3650, test_size=730, shuffle=False)\n",
        "print(disp_df[\"salida\"].describe())\n",
        "best_method=[{},{}]\n",
        "#Sin ajuste, Con ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAWBzDNM98je"
      },
      "source": [
        "## Modelo \"dummy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zP8qppDN9-dr",
        "outputId": "1aed75f8-b371-4b79-ae55-23fcc7954920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE del modelo 'dummy': 7668080.08840558\n",
            "MAE del modelo 'dummy': 6551109.50024395\n"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "regr_mean = DummyRegressor(strategy=\"mean\")\n",
        "regr_mean.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dummy = regr_mean.predict(X_test)\n",
        "\n",
        "rmse_dummy = np.sqrt(mean_squared_error(y_test, y_pred_dummy))\n",
        "mae_dummy = mean_absolute_error(y_test, y_pred_dummy)\n",
        "print(f\"RMSE del modelo 'dummy': {rmse_dummy}\")\n",
        "print(f\"MAE del modelo 'dummy': {mae_dummy}\")\n",
        "best_method[0][\"Dummy_RMSE\"]=rmse_dummy\n",
        "best_method[0][\"Dummy_MAE\"]=mae_dummy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A4FaQjGGR9Q"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlZZ6wb89LGC"
      },
      "source": [
        "Sin definir los hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puk9JmY2GPx1",
        "outputId": "df8f665d-235b-4e64-ae57-724e9a02fb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of the knn: 4597719.152116772\n",
            "MAE of the knn: 3253112.8767123288\n",
            "Hey: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "\n",
        "# X, y, X_train, X_test, y_train, y_test ya están definidos en el anterior código\n",
        "\n",
        "# We obtain predictions on the test set\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a KNN regressor\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# Train the model on the scaled training data\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "# Predict on the scaled test data\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_knn = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"RMSE of the knn: {rmse_knn}\")\n",
        "print(f\"MAE of the knn: {mae_knn}\")\n",
        "print(\"Hey:\", metrics.accuracy_score(y_pred, y_test))\n",
        "# Podemos observar que el RMSE y el MAE es muy alto, unos 3-4 millones, \n",
        "# pero tiene sentido si vemos que la media de los valores es del orden\n",
        "# de los 18 millones; por lo que el error no es tan grande, \n",
        "# son las unidades lo que aumenta ese valor.\n",
        "best_method[0][\"KNN_RMSE\"]=rmse_knn\n",
        "best_method[0][\"KNN_MAE\"]=mae_knn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk6vtfkyqlEa"
      },
      "source": [
        "Ajuste de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca3TWBcFqnhA",
        "outputId": "280c3197-07ae-4353-f2ec-f89f8432fa0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 70 candidates, totalling 70 fits\n",
            "RMSE de KNN con ajuste de hiperparámetros: 3745656.2902732617\n",
            "MAE de KNN con ajuste de hiperparámetros: 2654237.93209319\n",
            "{'metric': 'cityblock', 'n_neighbors': 12, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Search space\n",
        "param_grid = {'weights': ['uniform', 'distance'],\n",
        "              'n_neighbors': range(2,16,2),\n",
        "              'metric': ['cityblock', 'cosine', 'euclidean', 'manhattan', 'minkowski']}\n",
        "\n",
        "inner = PredefinedSplit(([-1] * 2920) + ([0] * 730))\n",
        "\n",
        "\n",
        "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
        "knn_hyper = GridSearchCV(KNeighborsRegressor(), \n",
        "                   param_grid,\n",
        "                   scoring='neg_mean_squared_error',\n",
        "                   cv=inner, \n",
        "                   n_jobs=1, verbose=1)\n",
        "\n",
        "# Train the self-adjusting process\n",
        "np.random.seed(42)\n",
        "knn_hyper.fit(X_train_scaled, y_train)\n",
        "y_test_pred = knn_hyper.predict(X_test_scaled)\n",
        "rmse_knn_hyper = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "mae_knn_hyper = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE de KNN con ajuste de hiperparámetros: {rmse_knn_hyper}\")\n",
        "print(f\"MAE de KNN con ajuste de hiperparámetros: {mae_knn_hyper}\")\n",
        "print(knn_hyper.best_params_)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train\n",
        "best_method[1][\"KNN_RMSE\"]=rmse_knn_hyper\n",
        "best_method[1][\"KNN_MAE\"]=mae_knn_hyper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z4DTqmJ2s0Z"
      },
      "source": [
        "##Árboles de regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fM9QfvH9PKx"
      },
      "source": [
        "Sin definir los hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5-5CDTs25Wj",
        "outputId": "3a30dbf8-3846-450f-d7f0-de61d115424e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of the tree: 4179665.0085206656\n",
            "MAE of the tree: 2933939.178082192\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "\n",
        "\n",
        "\n",
        "tree_regr = tree.DecisionTreeRegressor()\n",
        "np.random.seed(42) # reproducibility\n",
        "# We train it\n",
        "tree_regr.fit(X_train, y_train)\n",
        "# We obtain predictions on the test set\n",
        "y_test_pred = tree_regr.predict(X_test)\n",
        "# We compute accuracy\n",
        "rmse_tree = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "mae_tree = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE of the tree: {rmse_tree}\")\n",
        "print(f\"MAE of the tree: {mae_tree}\")\n",
        "\n",
        "# Pasa lo mismo que en el modelo de KNN, en el que tenemos\n",
        "# valores muy altos en \"salida\", y nos dan valores muy altos\n",
        "# en el MAE y en RMSE; pero más bajos que la media, por lo \n",
        "# que el error es menor que la media, y el modelo es aceptable\n",
        "best_method[0][\"TREE_RMSE\"]=rmse_tree\n",
        "best_method[0][\"TREE_MAE\"]=mae_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKtiAWhvFJ1f"
      },
      "source": [
        "Con ajustado de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpOiL_-BFMd3",
        "outputId": "e433ff62-a5ac-4988-8e81-265ea3319347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 64 candidates, totalling 64 fits\n",
            "RMSE del árbol con ajuste de hiperparámetros: 3437575.123783922\n",
            "MAE del árbol con ajuste de hiperparámetros: 2404698.5522945533\n",
            "{'max_depth': 4, 'min_samples_split': 2}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "\n",
        "# Search space\n",
        "param_grid = {'max_depth': range(2,10,1),\n",
        "              'min_samples_split': range(2,10,1)}\n",
        "\n",
        "inner = PredefinedSplit(([-1] * 2920) + ([0] * 730))\n",
        "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
        "tree_hyper = GridSearchCV(tree.DecisionTreeRegressor(), \n",
        "                   param_grid,\n",
        "                   scoring='neg_mean_squared_error',\n",
        "                   cv=inner, \n",
        "                   n_jobs=1, verbose=1)\n",
        "\n",
        "# Train the self-adjusting process\n",
        "np.random.seed(42)\n",
        "tree_hyper.fit(X_train, y_train)\n",
        "y_test_pred = tree_hyper.predict(X_test)\n",
        "rmse_tree_hyper = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "mae_tree_hyper = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE del árbol con ajuste de hiperparámetros: {rmse_tree_hyper}\")\n",
        "print(f\"MAE del árbol con ajuste de hiperparámetros: {mae_tree_hyper}\")\n",
        "print(tree_hyper.best_params_)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train\n",
        "best_method[1][\"TREE_RMSE\"]=rmse_tree_hyper\n",
        "best_method[1][\"TREE_MAE\"]=mae_tree_hyper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F6VKU1s53oP"
      },
      "source": [
        "##Regresor lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gt12qOY9SQy"
      },
      "source": [
        "Sin definir los hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BJOis1a58sX",
        "outputId": "fa4fd122-426c-45db-ca7d-4f75441202da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE del regresor lineal: 3052441.165997784\n",
            "MAE del regresor lineal: 2090908.836342777\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "LinReg = LinearRegression()\n",
        "np.random.seed(42) # reproducibility\n",
        "# We train it\n",
        "LinReg.fit(X_train, y_train)\n",
        "# We obtain predictions on the test set\n",
        "y_test_pred = LinReg.predict(X_test)\n",
        "# We compute accuracy\n",
        "LinReg_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "LinReg_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE del regresor lineal: {LinReg_rmse}\")\n",
        "print(f\"MAE del regresor lineal: {LinReg_mae}\")\n",
        "best_method[0][\"LR_RMSE\"]=LinReg_rmse\n",
        "best_method[0][\"LR_MAE\"]=LinReg_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NQLRAdutevw"
      },
      "source": [
        "Con ajuste de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "# Search space\n",
        "param_grid = {\n",
        " 'alpha': np.arange(0.00, 10000000, 100000)}\n",
        "inner = PredefinedSplit(([-1] * 2920) + ([0] * 730))\n",
        "\n",
        "\n",
        "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
        "knn_hyper = GridSearchCV(Ridge(), \n",
        "                   param_grid,\n",
        "                   scoring='neg_mean_squared_error',\n",
        "                   cv=inner, \n",
        "                   n_jobs=1, verbose=1)\n",
        "\n",
        "# Train the self-adjusting process\n",
        "np.random.seed(42)\n",
        "knn_hyper.fit(X_train_scaled, y_train)\n",
        "y_test_pred = knn_hyper.predict(X_test_scaled)\n",
        "rmse_lr_ridge = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "mae_lr_ridge = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE de Linear Regressor con ajuste de hiperparámetros (Ridge): {rmse_lr_ridge}\")\n",
        "print(f\"MAE de Linear Regressor con ajuste de hiperparámetros (Ridge): {mae_lr_ridge}\")\n",
        "print(knn_hyper.best_estimator_)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train\n",
        "best_method[1][\"RIDGE_RMSE\"]=rmse_lr_ridge\n",
        "best_method[1][\"RIDGE_MAE\"]=mae_lr_ridge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE1oj4qj5kX_",
        "outputId": "ed87ba27-6e5a-452a-e996-7fa6ff819b64"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 100 candidates, totalling 100 fits\n",
            "RMSE de Linear Regressor con ajuste de hiperparámetros (Ridge): 3052441.1659894427\n",
            "MAE de Linear Regressor con ajuste de hiperparámetros (Ridge): 2090908.8363355985\n",
            "Ridge(alpha=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "VL68Two0tdA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7381afaa-a22f-4a76-e6ce-5ce1eaf997df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+16, tolerance: 1.859e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:909: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE de Linear Regressor con ajuste de hiperparámetros (Lasso): 3745656.2902732617\n",
            "MAE de Linear Regressor con ajuste de hiperparámetros (Lasso): 2654237.93209319\n",
            "Lasso(alpha=0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+16, tolerance: 2.304e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Search space\n",
        "\"\"\"\n",
        "param_grid = {\n",
        " 'alpha': np.concatenate((np.arange(0.00, 1.0, 0.01),np.arange(0.00, 100.0, 1),np.arange(0.00, 10000.0, 100),np.arange(0.00, 1000000.0, 10000),np.arange(0.00, 100000000.0, 1000000))),\n",
        "}\n",
        "\"\"\"\n",
        "param_grid = {\n",
        " 'alpha': np.arange(0.00, 1000000, 100000)}\n",
        "inner = PredefinedSplit(([-1] * 2920) + ([0] * 730))\n",
        "\n",
        "\n",
        "# Definition of a 2-step process that self-adjusts 2 hyperpars\n",
        "knn_hyper = GridSearchCV(Lasso(), \n",
        "                   param_grid,\n",
        "                   scoring='neg_mean_squared_error',\n",
        "                   cv=inner, \n",
        "                   n_jobs=1, verbose=1)\n",
        "\n",
        "# Train the self-adjusting process\n",
        "np.random.seed(42)\n",
        "knn_hyper.fit(X_train_scaled, y_train)\n",
        "y_test_pred = knn_hyper.predict(X_test_scaled)\n",
        "rmse_lr_lasso = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
        "mae_lr_lasso = mean_absolute_error(y_test, y_test_pred)\n",
        "print(f\"RMSE de Linear Regressor con ajuste de hiperparámetros (Lasso): {rmse_knn_hyper}\")\n",
        "print(f\"MAE de Linear Regressor con ajuste de hiperparámetros (Lasso): {mae_knn_hyper}\")\n",
        "print(knn_hyper.best_estimator_)\n",
        "\n",
        "# At this point, regr contains the model with the best hyper-parameters found by gridsearch\n",
        "# and trained on the complete X_train\n",
        "best_method[1][\"LASSO_RMSE\"]=rmse_lr_lasso\n",
        "best_method[1][\"LASSO_MAE\"]=mae_lr_lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusiones métodos básicos\n"
      ],
      "metadata": {
        "id": "doK4hk4stPZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la comparación vamos a primero ver la clasificación con hiperparametros por omisión: \n",
        "Mejor RMSE:\n",
        "Mejor MAE: \n",
        "Mejor tiempo:\n"
      ],
      "metadata": {
        "id": "CPRscn76uGhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Errores sin ajuste de híperparámetros\\n\")\n",
        "for i in best_method[0]:\n",
        "  print(i+\": \\t\",best_method[0][i])\n",
        "\n",
        "print(\"\\nErrores con ajuste de híperparámetros\\n\")\n",
        "for i in best_method[1]:\n",
        "  print(i+\": \\t\",best_method[1][i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsT8JyUdyTuR",
        "outputId": "5ad28591-e0be-4f67-f1ee-6e30c6c60680"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errores sin ajuste de híperparámetros\n",
            "\n",
            "Dummy_RMSE: \t 7668080.08840558\n",
            "Dummy_MAE: \t 6551109.50024395\n",
            "KNN_RMSE: \t 4597719.152116772\n",
            "KNN_MAE: \t 3253112.8767123288\n",
            "TREE_RMSE: \t 4179665.0085206656\n",
            "TREE_MAE: \t 2933939.178082192\n",
            "LR_RMSE: \t 3052441.165997784\n",
            "LR_MAE: \t 2090908.836342777\n",
            "\n",
            "Errores con ajuste de híperparámetros\n",
            "\n",
            "KNN_RMSE: \t 3745656.2902732617\n",
            "KNN_MAE: \t 2654237.93209319\n",
            "TREE_RMSE: \t 3437575.123783922\n",
            "TREE_MAE: \t 2404698.5522945533\n",
            "RIDGE_RMSE: \t 3052441.1659894427\n",
            "RIDGE_MAE: \t 2090908.8363355985\n",
            "LASSO_RMSE: \t 3047675.695198696\n",
            "LASSO_MAE: \t 2067323.268974352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En ambos casos podemos observar que el método con mínimo error es la regressión lineal. También podemos ver que el método Dummy es el que mayor error tiene, como era de esperar.\n",
        "\n",
        "También y como era predecible, el ajuste de hiperparámetros siempre supone una mejora sustancial. Ya que los valores por omisión emplean unos hiperparámetros por defecto, resulta obvio que estos no van a ser los mejores para el caso particular en el que nos encontramos."
      ],
      "metadata": {
        "id": "hSO9sNt_3HSO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}